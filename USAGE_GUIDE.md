# ğŸš€ Transformer ä¸­é—´çŠ¶æ€åˆ†æå™¨ - å®Œæ•´ç¤ºä¾‹é›†åˆ

æ‚¨ç°åœ¨æ‹¥æœ‰ä¸€ä¸ªåŠŸèƒ½å¼ºå¤§çš„ Transformer æ¨¡å‹ä¸­é—´çŠ¶æ€åˆ†æå·¥å…·ï¼ä»¥ä¸‹æ˜¯å„ç§ä½¿ç”¨ç¤ºä¾‹å’Œå®é™…åº”ç”¨åœºæ™¯ã€‚

## ğŸ“š å¯ç”¨ç¤ºä¾‹æ–‡ä»¶

### 1. **åŸºç¡€ç¤ºä¾‹** (`examples.py`)
åŒ…å«6ä¸ªæ ¸å¿ƒåŠŸèƒ½æ¼”ç¤ºï¼š

```bash
python3 examples.py 1    # åŸºç¡€æ–‡æœ¬åˆ†æ
python3 examples.py 2    # æ³¨æ„åŠ›åˆ†æ  
python3 examples.py 3    # Token æ¯”è¾ƒ
python3 examples.py 4    # åæ ‡ç³»ç»Ÿ
python3 examples.py 5    # è‡ªå®šä¹‰åˆ†æ
python3 examples.py 6    # å¯è§†åŒ–
python3 examples.py      # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
```

### 2. **å®é™…åº”ç”¨æ¼”ç¤º** (`real_world_demos.py`)
åŒ…å«6ä¸ªçœŸå®åœºæ™¯åº”ç”¨ï¼š

```bash
python3 real_world_demos.py 1    # æƒ…æ„Ÿåˆ†æ
python3 real_world_demos.py 2    # è¯æ±‡ç›¸ä¼¼æ€§
python3 real_world_demos.py 3    # æ³¨æ„åŠ›æ¨¡å¼
python3 real_world_demos.py 4    # è¯­è¨€ç°è±¡
python3 real_world_demos.py 5    # å¤šè¯­è¨€åˆ†æ
python3 real_world_demos.py 6    # æ€§èƒ½åˆ†æ
python3 real_world_demos.py      # è¿è¡Œæ‰€æœ‰æ¼”ç¤º
```

## ğŸ¯ å¿«é€Ÿå¼€å§‹ç¤ºä¾‹

### æœ€ç®€å•çš„ä½¿ç”¨æ–¹å¼
```python
from main import TransformerInspector

# åˆ›å»ºåˆ†æå™¨å¹¶åŠ è½½æ¨¡å‹
inspector = TransformerInspector()
inspector.load_model("gpt2")

# åˆ†ææ–‡æœ¬
result = inspector.analyze_text(
    text="Hello transformer analysis world!",
    target_tokens=["transformer", "analysis"],
    export_formats=["json", "csv"]
)

# æŸ¥çœ‹ç»“æœ
print(f"åˆ†æäº† {result['analysis_report']['summary']['total_tokens']} ä¸ª tokens")
```

### åˆšæ‰è¿è¡Œçš„æƒ…æ„Ÿåˆ†æç¤ºä¾‹ç»“æœ
```
ğŸ­ æƒ…æ„Ÿåˆ†æç»“æœ:
æ­£é¢å¥å­: "I absolutely love this amazing product!"
- ' love' (æ­£é¢): å‡å€¼èŒƒæ•° = 147.721
- ' amazing' (æ­£é¢): å‡å€¼èŒƒæ•° = 137.936

è´Ÿé¢å¥å­: "I completely hate this terrible product!"  
- ' hate' (è´Ÿé¢): å‡å€¼èŒƒæ•° = 143.799
- ' terrible' (è´Ÿé¢): å‡å€¼èŒƒæ•° = 129.263
```

## ğŸ”¥ æ¨èä½¿ç”¨åœºæ™¯

### 1. **NLP ç ”ç©¶**
- åˆ†ææ¨¡å‹å¦‚ä½•å¤„ç†ä¸åŒç±»å‹çš„è¯æ±‡
- ç ”ç©¶æ³¨æ„åŠ›æ¨¡å¼å’Œè¯­æ³•å…³ç³»
- æ¯”è¾ƒåŒä¹‰è¯åœ¨ä¸åŒä¸Šä¸‹æ–‡ä¸­çš„è¡¨ç¤º

### 2. **æ¨¡å‹è°ƒè¯•**
- å®šä½æ¨¡å‹åœ¨å¤„ç†ç‰¹å®šè¾“å…¥æ—¶çš„é—®é¢˜
- åˆ†æä¸­é—´å±‚çš„æ¿€æ´»æ¨¡å¼
- ç›‘æ§æ¨¡å‹æ€§èƒ½å’Œèµ„æºä½¿ç”¨

### 3. **æ•™è‚²å’Œå­¦ä¹ **
- å¯è§†åŒ– Transformer çš„å†…éƒ¨å·¥ä½œåŸç†
- ç†è§£æ³¨æ„åŠ›æœºåˆ¶çš„å®é™…æ•ˆæœ
- æ¢ç´¢è¯æ±‡è¯­ä¹‰çš„å‘é‡è¡¨ç¤º

### 4. **æ¨¡å‹æ¯”è¾ƒ**
- å¯¹æ¯”ä¸åŒæ¨¡å‹å¯¹ç›¸åŒè¾“å…¥çš„å¤„ç†
- åˆ†ææ¨¡å‹ç‰ˆæœ¬é—´çš„å·®å¼‚
- è¯„ä¼°æ¨¡å‹åœ¨ç‰¹å®šä»»åŠ¡ä¸Šçš„è¡¨ç°

## ğŸ“Š è¾“å‡ºæ–‡ä»¶è¯´æ˜

è¿è¡Œç¤ºä¾‹åï¼Œåœ¨ `./outputs/` ç›®å½•ä¸­æ‚¨ä¼šæ‰¾åˆ°ï¼š

```
outputs/
â”œâ”€â”€ analysis_unknown.json.gz    # å®Œæ•´åˆ†æç»“æœ (JSONå‹ç¼©æ ¼å¼)
â”œâ”€â”€ analysis_unknown.csv        # Tokenè½¨è¿¹æ•°æ® (è¡¨æ ¼æ ¼å¼)  
â”œâ”€â”€ analysis_unknown.npz        # å¼ é‡æ•°æ® (NumPyæ ¼å¼)
â”œâ”€â”€ attention_heatmap.png        # æ³¨æ„åŠ›çƒ­å›¾ (å¦‚æœç”Ÿæˆå¯è§†åŒ–)
â””â”€â”€ token_trajectory.png        # Tokenè½¨è¿¹å›¾ (å¦‚æœç”Ÿæˆå¯è§†åŒ–)
```

### JSON æ–‡ä»¶ç»“æ„
```json
{
  "metadata": {
    "model_type": "gpt2",
    "total_tokens": 7,
    "analysis_timestamp": "..."
  },
  "token_analysis": {
    "position_2": {
      "token_text": " love",
      "trajectory_layers": [0, 1, 2, ...],
      "hidden_state_norms": [55.68, 55.99, ...],
      "attention_weights": {...}
    }
  },
  "coordinate_data": {...}
}
```

## ğŸ› ï¸ é«˜çº§è‡ªå®šä¹‰

### è‡ªå®šä¹‰ Hook ç³»ç»Ÿ
```python
from hook_system import IntermediateInspector

# åªç›‘æ§ç‰¹å®šå±‚
inspector = IntermediateInspector(model, capture_attention=True)
inspector.register_hooks(layer_patterns=["transformer.h.0", "transformer.h.5"])

# æ‰§è¡Œåˆ†æ
result = inspector.capture_forward_pass(inputs)
```

### ç²¾ç¡®åæ ‡ç®¡ç†
```python
from coordinate_system import CoordinateManager

manager = CoordinateManager("gpt2")

# ä¸ºç‰¹å®šä½ç½®åˆ›å»ºåæ ‡
coord = manager.create_coordinate(
    batch_idx=0, sequence_idx=2, layer_idx=5,
    module_type="attention", head_idx=3
)

# å­˜å‚¨å˜é‡
manager.add_variable(coord, tensor_data, "æè¿°")
```

### æ‰¹é‡åˆ†æ
```python
texts = [
    "Positive sentiment text",
    "Negative sentiment text", 
    "Neutral sentiment text"
]

results = []
for text in texts:
    result = inspector.analyze_text(text=text, target_tokens=["sentiment"])
    results.append(result)
```

## ğŸ”§ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

1. **å†…å­˜ä¸è¶³**
   - ä½¿ç”¨è¾ƒçŸ­çš„æ–‡æœ¬è¿›è¡Œæµ‹è¯•
   - å‡å°‘ `export_formats` é€‰é¡¹
   - ç¡®ä¿æœ‰è¶³å¤Ÿçš„ GPU å†…å­˜

2. **æ‰¾ä¸åˆ°ç›®æ ‡ Token**
   - æ£€æŸ¥ token çš„ç¡®åˆ‡æ‹¼å†™ï¼ˆæ³¨æ„ç©ºæ ¼ï¼‰
   - ä½¿ç”¨ `target_tokens=None` åˆ†ææ‰€æœ‰ tokens
   - æŸ¥çœ‹ token åˆ†è§£ç»“æœï¼š`token_info['tokens']`

3. **å¯¼å‡ºæ–‡ä»¶è¿‡å¤§**
   - ä½¿ç”¨ `["json"]` è€Œä¸æ˜¯æ‰€æœ‰æ ¼å¼
   - é™åˆ¶åˆ†æçš„ token æ•°é‡
   - æ£€æŸ¥ `.gitignore` é¿å…æäº¤å¤§æ–‡ä»¶

### æ€§èƒ½ä¼˜åŒ–å»ºè®®

```python
# ä½¿ç”¨è¾ƒå°çš„æ¨¡å‹è¿›è¡Œæµ‹è¯•
inspector.load_model("distilgpt2")  # æ›´å°æ›´å¿«

# åªåˆ†æå…³é”® tokens
result = inspector.analyze_text(
    text=long_text,
    target_tokens=["å…³é”®è¯1", "å…³é”®è¯2"],  # è€Œä¸æ˜¯æ‰€æœ‰ tokens
    export_formats=["json"]  # åªä½¿ç”¨å¿…è¦çš„æ ¼å¼
)
```

## ğŸ“ˆ æ‰©å±•åŠŸèƒ½

è¿™ä¸ªå·¥å…·è®¾è®¡ä¸ºæ¨¡å—åŒ–ï¼Œæ‚¨å¯ä»¥è½»æ¾æ‰©å±•ï¼š

1. **æ·»åŠ æ–°æ¨¡å‹**: åœ¨ `ModelLoader` ä¸­æ”¯æŒæ›´å¤šæ¨¡å‹ç±»å‹
2. **è‡ªå®šä¹‰æŒ‡æ ‡**: æ‰©å±• `TokenTracker` çš„åˆ†æåŠŸèƒ½
3. **æ–°å¯¼å‡ºæ ¼å¼**: åœ¨ `DataExporter` ä¸­æ·»åŠ æ ¼å¼æ”¯æŒ  
4. **å¯è§†åŒ–å¢å¼º**: æ‰©å±•ç»˜å›¾å’ŒæŠ¥å‘ŠåŠŸèƒ½

## ğŸ‰ å¼€å§‹æ¢ç´¢ï¼

ç°åœ¨æ‚¨æœ‰äº†å®Œæ•´çš„å·¥å…·å’Œç¤ºä¾‹é›†åˆï¼å»ºè®®ä»ä»¥ä¸‹æ­¥éª¤å¼€å§‹ï¼š

1. **è¿è¡ŒåŸºç¡€ç¤ºä¾‹**: `python3 examples.py 1`
2. **å°è¯•å®é™…åº”ç”¨**: `python3 real_world_demos.py 1`  
3. **åˆ†ææ‚¨è‡ªå·±çš„æ–‡æœ¬**: ä¿®æ”¹ç¤ºä¾‹ä¸­çš„ `text` å˜é‡
4. **æ¢ç´¢è¾“å‡ºæ–‡ä»¶**: æŸ¥çœ‹ `./outputs/` ç›®å½•
5. **è‡ªå®šä¹‰åˆ†æ**: æ ¹æ®æ‚¨çš„éœ€æ±‚ä¿®æ”¹å‚æ•°

ç¥æ‚¨ä½¿ç”¨æ„‰å¿«ï¼ğŸš€